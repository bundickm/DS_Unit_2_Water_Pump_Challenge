{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simplified Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEpulDa+c400ne7z2ws1xt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bundickm/Predictive_Preventative_Maintenance/blob/master/notebooks/Simplified_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht7ys9OZDVmo",
        "colab_type": "text"
      },
      "source": [
        "## Imports, Installs, and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxkqQozoDVnC",
        "colab_type": "code",
        "outputId": "4f4e1521-1876-4e83-9870-d5ab109accbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "pip install category_encoders"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.25.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.6.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oecpRb_gDVnP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyDwKY_vDVnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure we can see all columns\n",
        "pd.set_option('display.max_columns', 100)\n",
        "\n",
        "def reset():\n",
        "    #Create a function to quickly and easily reset our data\n",
        "    \n",
        "    # Read in all CSV's\n",
        "    X_train = pd.read_csv('https://raw.githubusercontent.com/bundickm/Kaggle_Water_Pump_Competition/master/train_features.csv')\n",
        "    X_test = pd.read_csv('https://raw.githubusercontent.com/bundickm/Kaggle_Water_Pump_Competition/master/test_features.csv')\n",
        "    y_train = pd.read_csv('https://raw.githubusercontent.com/bundickm/Kaggle_Water_Pump_Competition/master/train_labels.csv')\n",
        "\n",
        "    # Split X_train to training and validation\n",
        "    return train_test_split(X_train, y_train, random_state=42, test_size=.2)\n",
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QS0vkR0KvxU",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37egMsuxDVp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correct_distribution_issues(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # amount_tsh\n",
        "    mask = (df['amount_tsh'] > 1500)\n",
        "    tsh_mean = df[df['amount_tsh'] > 0]['amount_tsh'].mean()\n",
        "    df.loc[mask, 'amount_tsh'] = tsh_mean\n",
        "\n",
        "    # population\n",
        "    df.loc[df['population'] == 0, 'population'] = df.groupby(\n",
        "                                 'region_code')['population'].transform('mean')\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81PMJhG1DVp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_lowercase(df):\n",
        "    df = df.copy()\n",
        "    \n",
        "    cols = df.select_dtypes(include='object').columns\n",
        "    for col in cols:\n",
        "      try:\n",
        "        df[col] = df[col].str.lower()\n",
        "      except:\n",
        "        pass\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkPTFVvoDVpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lat_long_correction(df):\n",
        "    df = df.copy()\n",
        "    \n",
        "    # latitude has a floating point precision error so we are selecting via the `>` comparison operator\n",
        "    df.loc[df['longitude'] == 0, 'longitude'] = df.groupby(\n",
        "                                 'region_code')['longitude'].transform('mean')\n",
        "    df.loc[df['latitude'] > -.001, 'latitude'] = df.groupby(\n",
        "                                 'region_code')['latitude'].transform('mean')\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FcvPFDi8LDks",
        "colab": {}
      },
      "source": [
        "def cleaning(df):\n",
        "    df = df.copy()\n",
        "    df = to_lowercase(df)\n",
        "    df = lat_long_correction(df)\n",
        "    df = correct_distribution_issues(df)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QETn7rhIDVqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_engineer(df):\n",
        "    df = df.copy()\n",
        "        \n",
        "    df = cleaning(df)\n",
        "\n",
        "    df = df[['quantity', 'extraction_type_class', 'waterpoint_type',\n",
        "             'amount_tsh', 'population', 'latitude', 'longitude']]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kbOlXNGbexD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = reset()\n",
        "X_train = feature_engineer(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwXTEPISc70b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode our categoricals\n",
        "encoder = ce.OrdinalEncoder()\n",
        "X_train = encoder.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K3RTuStKp1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "40dde242-f198-4403-8159-f02d5b6a53ba"
      },
      "source": [
        "\n",
        "\n",
        "forest = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "\n",
        "param_distributions = {'n_estimators':[200],\n",
        "                       'max_depth':[20]}\n",
        "\n",
        "search = RandomizedSearchCV(forest, param_distributions=param_distributions,\n",
        "                            scoring='accuracy', n_iter=1, n_jobs=-1, cv=5,\n",
        "                            verbose=10, return_train_score=True, \n",
        "                            random_state=42)\n",
        "search.fit(X_train, y_train['status_group'])\n",
        "\n",
        "print('Training Accuracy Score:', search.best_score_)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   18.2s\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   38.2s remaining:   25.5s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   47.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   47.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy Score: 0.7880892255892256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYjSS6_bMg3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c5a1d5a-f86e-4638-d115-17ad5a164e34"
      },
      "source": [
        "best = search.best_estimator_\n",
        "X_val = feature_engineer(X_val)\n",
        "X_val = encoder.transform(X_val)\n",
        "y_pred = best.predict(X_val)\n",
        "print('Validation Set Accuracy Score:', \n",
        "      accuracy_score(y_val['status_group'], y_pred))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Set Accuracy Score: 0.7956228956228957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiI-72vRNZFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8a50361-0693-4f58-f6f3-e60ca8198d6d"
      },
      "source": [
        "dump(best, 'model.joblib', compress=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}